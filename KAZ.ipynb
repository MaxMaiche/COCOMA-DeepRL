{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAZ env  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.butterfly import knights_archers_zombies_v10\n",
    "from pettingzoo.utils.conversions import aec_to_parallel\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 DQN pour tous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angeleramauge/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.18GB > 1.84GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1720     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 848      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00599  |\n",
      "|    n_updates        | 46       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1778     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1584     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 92       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1798     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2320     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000324 |\n",
      "|    n_updates        | 138      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1849     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2976     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000103 |\n",
      "|    n_updates        | 179      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1849     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3632     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000337 |\n",
      "|    n_updates        | 220      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1849     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4288     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000397 |\n",
      "|    n_updates        | 261      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1846     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4944     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000596 |\n",
      "|    n_updates        | 302      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1868     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000213 |\n",
      "|    n_updates        | 368      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1871     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 6656     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000118 |\n",
      "|    n_updates        | 409      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1865     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 7552     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00025  |\n",
      "|    n_updates        | 465      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1861     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 8208     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000194 |\n",
      "|    n_updates        | 506      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1870     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 9024     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.45e-05 |\n",
      "|    n_updates        | 557      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1872     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 9760     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000169 |\n",
      "|    n_updates        | 603      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angeleramauge/anaconda3/lib/python3.11/site-packages/supersuit/vector/sb3_vector_wrapper.py:52: UserWarning: PettingZoo environments do not take the `render(mode)` argument, to change rendering mode, re-initialize the environment using the `render_mode` argument.\n",
      "  warnings.warn(\n",
      "/Users/angeleramauge/anaconda3/lib/python3.11/site-packages/pettingzoo/butterfly/knights_archers_zombies/knights_archers_zombies.py:799: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode.\u001b[0m\n",
      "  gymnasium.logger.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Charger l'environnement PettingZoo AEC (par défaut)\n",
    "aec_env = knights_archers_zombies_v10.env()\n",
    "\n",
    "# Convertir l'environnement AEC en ParallelEnv\n",
    "parallel_env = aec_to_parallel(aec_env)\n",
    "\n",
    "# Appliquer le wrapper 'black_death_v3' pour gérer les agents inactifs\n",
    "parallel_env = ss.black_death_v3(parallel_env)\n",
    "\n",
    "# Utiliser SuperSuit pour convertir l'environnement en un environnement Gym compatible\n",
    "gym_env = ss.pettingzoo_env_to_vec_env_v1(parallel_env)\n",
    "gym_env = ss.concat_vec_envs_v1(gym_env, 1, base_class='stable_baselines3')\n",
    "\n",
    "# Initialiser le modèle DQN\n",
    "model = DQN('MlpPolicy', gym_env, verbose=1)\n",
    "\n",
    "# Entraîner l'agent\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"dqn_knights_archers_zombies\")\n",
    "\n",
    "# Charger le modèle pour l'utiliser ou l'évaluer\n",
    "model = DQN.load(\"dqn_knights_archers_zombies\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "env = knights_archers_zombies_v10.parallel_env()\n",
    "env = ss.black_death_v3(env)\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "env = ss.concat_vec_envs_v1(env, 1, base_class='stable_baselines3')\n",
    "model.set_env(env)\n",
    "\n",
    "obs = env.reset()\n",
    "rewards = []\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    if done.any():\n",
    "        obs = env.reset()\n",
    "\n",
    "# Afficher les récompenses\n",
    "plt.plot(np.cumsum(rewards))\n",
    "plt.show()\n",
    "\n",
    "# # Make a video of the trained model\n",
    "# env = knights_archers_zombies_v10.parallel_env()\n",
    "# env = ss.black_death_v3(env)\n",
    "# env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "# env = ss.concat_vec_envs_v1(env, 1, base_class='stable_baselines3')\n",
    "# model.set_env(env)\n",
    "# ss.record_video(env, model, \"dqn_knights_archers_zombies.mp4\", video_length=1000, fps=10)\n",
    "\n",
    "# # Afficher la vidéo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 DQN indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Temps écoulé: 00:00:00 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angeleramauge/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'checkpoints' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 - Temps écoulé: 00:02:18 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 3 - Temps écoulé: 00:04:38 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 4 - Temps écoulé: 00:06:57 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 5 - Temps écoulé: 00:09:17 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 6 - Temps écoulé: 00:11:37 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 7 - Temps écoulé: 00:13:57 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 8 - Temps écoulé: 00:16:17 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 9 - Temps écoulé: 00:18:38 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 10 - Temps écoulé: 00:21:00 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 11 - Temps écoulé: 00:23:21 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 12 - Temps écoulé: 00:25:41 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 13 - Temps écoulé: 00:28:01 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 14 - Temps écoulé: 00:30:20 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 15 - Temps écoulé: 00:32:40 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 16 - Temps écoulé: 00:35:00 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 17 - Temps écoulé: 00:37:21 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 18 - Temps écoulé: 00:39:42 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 19 - Temps écoulé: 00:42:04 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Episode 20 - Temps écoulé: 00:44:25 s\n",
      "Step 0/10000\n",
      "Step 1000/10000\n",
      "Step 2000/10000\n",
      "Step 3000/10000\n",
      "Step 4000/10000\n",
      "Step 5000/10000\n",
      "Step 6000/10000\n",
      "Step 7000/10000\n",
      "Step 8000/10000\n",
      "Step 9000/10000\n",
      "Entraînement terminé !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger l'environnement PettingZoo AEC (par défaut)\n",
    "aec_env = knights_archers_zombies_v10.env()\n",
    "\n",
    "# Convertir l'environnement AEC en ParallelEnv\n",
    "parallel_env = aec_to_parallel(aec_env)\n",
    "\n",
    "# Appliquer le wrapper 'black_death_v3' pour gérer les agents inactifs\n",
    "parallel_env = ss.black_death_v3(parallel_env)\n",
    "\n",
    "# Utiliser SuperSuit pour convertir l'environnement en un environnement Gym compatible\n",
    "gym_env = ss.pettingzoo_env_to_vec_env_v1(parallel_env)\n",
    "gym_env = ss.concat_vec_envs_v1(gym_env, 1, base_class='stable_baselines3')\n",
    "\n",
    "# Initialiser les modèles DQN pour chaque agent\n",
    "num_agents = gym_env.num_envs  # Récupérer le nombre d'agents à partir de l'environnement\n",
    "models_archer = [DQN(  \n",
    "                'MlpPolicy', \n",
    "                gym_env, \n",
    "                verbose=0,\n",
    "                learning_rate=0.001,\n",
    "                buffer_size=10000,\n",
    "                batch_size=64,\n",
    "                learning_starts=200,\n",
    "                train_freq=1,\n",
    "                gradient_steps=1,\n",
    "                target_update_interval=100,\n",
    "                exploration_fraction=0.3,\n",
    "                exploration_initial_eps=0.05,\n",
    "                exploration_final_eps=0.03,\n",
    "                gamma=0.96\n",
    "\n",
    "            ) for _ in range(2)]\n",
    "\n",
    "models_knight = [DQN(  \n",
    "                'MlpPolicy', \n",
    "                gym_env, \n",
    "                verbose=0,\n",
    "                learning_rate=0.001,\n",
    "                buffer_size=10000,\n",
    "                batch_size=64,\n",
    "                learning_starts=200,\n",
    "                train_freq=1,\n",
    "                gradient_steps=1,\n",
    "                target_update_interval=100,\n",
    "                exploration_fraction=0.3,\n",
    "                exploration_initial_eps=0.05,\n",
    "                exploration_final_eps=0.03,\n",
    "                gamma=0.96\n",
    "            ) for _ in range(2)]\n",
    "\n",
    "models = models_archer + models_knight\n",
    "\n",
    "### TODO TRAIN AGENT INDENPENDENTLY FIRST THEN TRAIN THEM TOGETHER\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "# Entraîner les agents\n",
    "timesteps = 10_000\n",
    "nb_episodes = 20\n",
    "for episode in range(nb_episodes):  # Nombre d'épisodes d'entraînement\n",
    "    t = time.time() - start_t\n",
    "    hours, remainder = divmod(t, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Episode {episode + 1} - Temps écoulé: {int(hours):02}:{int(minutes):02}:{int(seconds):02} s\")\n",
    "    obs = gym_env.reset()\n",
    "    done = np.array([False] * num_agents)\n",
    "\n",
    "    for step in range(timesteps):\n",
    "        if step % 1000 == 0:\n",
    "            print(f\"Step {step}/{timesteps}\")\n",
    "        actions = np.array([models[i].predict(obs[i])[0] for i in range(num_agents)])  # Prédire les actions pour chaque agent\n",
    "        obs, rewards_batch, done, _ = gym_env.step(actions)  # Appliquer les actions dans l'environnement\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            models[i].learn(total_timesteps=1)  # Mettre à jour chaque agent après chaque étape\n",
    "        \n",
    "        if done.all():\n",
    "            obs = gym_env.reset()\n",
    "            done = np.array([False] * num_agents)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        models[i].learn(total_timesteps=100)\n",
    "\n",
    "    # Sauvegarder les modèles\n",
    "    for i in range(num_agents):\n",
    "        models[i].save(f\"./checkpoints/dqn_agent_{i + 1}_knights_archers_zombies_{episode}\")\n",
    "\n",
    "# Sauvegarder les modèles\n",
    "for i in range(num_agents):\n",
    "    models[i].save(f\"dqn_agent_{i + 1}_knights_archers_zombies\")\n",
    "\n",
    "print(\"Entraînement terminé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration du réseau Q pour chaque agent\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # Adjust input_dim to match actual observation dimension\n",
    "        self.fc2 = nn.Linear(64, action_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# Fonction de sélection d'action avec epsilon-greedy\n",
    "def select_action(state, q_net, epsilon, action_dim):\n",
    "    if random.random() < epsilon:\n",
    "        action = random.randint(0, action_dim - 1)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state = torch.FloatTensor(state.flatten())  \n",
    "            q_values = q_net(state)\n",
    "            action = torch.argmax(q_values).item()\n",
    "    return action\n",
    "\n",
    "# Buffer de replay pour stocker les expériences de chaque agent\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 203/200000 (0.102%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 366/200000 (0.183%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 529/200000 (0.265%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 732/200000 (0.366%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 895/200000 (0.448%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 1058/200000 (0.529%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 1241/200000 (0.62%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 1464/200000 (0.732%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 1627/200000 (0.814%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 1850/200000 (0.925%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 2013/200000 (1.006%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 2176/200000 (1.088%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 2339/200000 (1.169%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 2502/200000 (1.251%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 2745/200000 (1.372%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 2988/200000 (1.494%) - Rewards: (-1, 3, -1, -1)\n",
      "Steps 3151/200000 (1.576%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 3314/200000 (1.657%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 3517/200000 (1.758%) - Rewards: (1, -1, -1, 0)\n",
      "Steps 3680/200000 (1.84%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 3903/200000 (1.952%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 4086/200000 (2.043%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 4289/200000 (2.144%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 4532/200000 (2.266%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 4755/200000 (2.377%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 4978/200000 (2.489%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 5141/200000 (2.571%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 5324/200000 (2.662%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 5487/200000 (2.744%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 5650/200000 (2.825%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 5813/200000 (2.906%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 5976/200000 (2.988%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 6139/200000 (3.07%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 6302/200000 (3.151%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 6465/200000 (3.232%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 6628/200000 (3.314%) - Rewards: (-1, 0, -1, 0)\n",
      "Steps 6791/200000 (3.395%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 7014/200000 (3.507%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 7217/200000 (3.608%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 7440/200000 (3.72%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 7603/200000 (3.801%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 7786/200000 (3.893%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 7989/200000 (3.994%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 8152/200000 (4.076%) - Rewards: (0, 3, -1, -1)\n",
      "Steps 8335/200000 (4.167%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 8498/200000 (4.249%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 8661/200000 (4.331%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 8824/200000 (4.412%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 8987/200000 (4.494%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 9150/200000 (4.575%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 9313/200000 (4.657%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 9476/200000 (4.738%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 9639/200000 (4.82%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 9802/200000 (4.901%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 9965/200000 (4.982%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 10148/200000 (5.074%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 10331/200000 (5.165%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 10514/200000 (5.257%) - Rewards: (1, 0, -1, 0)\n",
      "Steps 10677/200000 (5.338%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 10860/200000 (5.43%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 11063/200000 (5.532%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 11226/200000 (5.613%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 11409/200000 (5.704%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 11572/200000 (5.786%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 11735/200000 (5.867%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 11898/200000 (5.949%) - Rewards: (-1, 4, -1, -1)\n",
      "Steps 12081/200000 (6.04%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 12264/200000 (6.132%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 12427/200000 (6.214%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 12590/200000 (6.295%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 12753/200000 (6.377%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 12956/200000 (6.478%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 13119/200000 (6.559%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 13302/200000 (6.651%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 13465/200000 (6.732%) - Rewards: (-1, -1, 0, 0)\n",
      "Steps 13648/200000 (6.824%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 13811/200000 (6.906%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 13994/200000 (6.997%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 14197/200000 (7.099%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 14400/200000 (7.2%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 14563/200000 (7.282%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 14726/200000 (7.363%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 14889/200000 (7.444%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 15052/200000 (7.526%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 15235/200000 (7.618%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 15398/200000 (7.699%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 15621/200000 (7.81%) - Rewards: (-1, 4, -1, -1)\n",
      "Steps 15844/200000 (7.922%) - Rewards: (-1, 4, -1, -1)\n",
      "Steps 16027/200000 (8.014%) - Rewards: (-1, 3, -1, -1)\n",
      "Steps 16190/200000 (8.095%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 16353/200000 (8.177%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 16516/200000 (8.258%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 16679/200000 (8.339%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 16842/200000 (8.421%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 17065/200000 (8.533%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 17228/200000 (8.614%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 17431/200000 (8.716%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 17594/200000 (8.797%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 17757/200000 (8.879%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 17920/200000 (8.96%) - Rewards: (-1, -1, 1, -1)\n",
      "Steps 18083/200000 (9.041%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 18246/200000 (9.123%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 18409/200000 (9.204%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 18612/200000 (9.306%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 18795/200000 (9.398%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 18998/200000 (9.499%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 19241/200000 (9.62%) - Rewards: (0, 2, 0, -1)\n",
      "Steps 19424/200000 (9.712%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 19587/200000 (9.793%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 19750/200000 (9.875%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 19933/200000 (9.966%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 20096/200000 (10.048%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 20399/200000 (10.2%) - Rewards: (4, 0, 0, -1)\n",
      "Steps 20562/200000 (10.281%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 20725/200000 (10.362%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 20888/200000 (10.444%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 21051/200000 (10.526%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 21314/200000 (10.657%) - Rewards: (0, 5, -1, -1)\n",
      "Steps 21477/200000 (10.739%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 21640/200000 (10.82%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 21803/200000 (10.902%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 21966/200000 (10.983%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 22129/200000 (11.064%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 22372/200000 (11.186%) - Rewards: (2, 3, -1, -1)\n",
      "Steps 22575/200000 (11.287%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 22738/200000 (11.369%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 22961/200000 (11.481%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 23144/200000 (11.572%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 23307/200000 (11.653%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 23490/200000 (11.745%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 23673/200000 (11.836%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 23856/200000 (11.928%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 24059/200000 (12.03%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 24242/200000 (12.121%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 24405/200000 (12.202%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 24568/200000 (12.284%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 24731/200000 (12.366%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 24894/200000 (12.447%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 25077/200000 (12.538%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 25260/200000 (12.63%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 25423/200000 (12.712%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 25586/200000 (12.793%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 25749/200000 (12.874%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 25952/200000 (12.976%) - Rewards: (-1, 1, 0, -1)\n",
      "Steps 26135/200000 (13.068%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 26298/200000 (13.149%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 26461/200000 (13.231%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 26624/200000 (13.312%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 26787/200000 (13.393%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 26950/200000 (13.475%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 27113/200000 (13.556%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 27316/200000 (13.658%) - Rewards: (0, 3, -1, -1)\n",
      "Steps 27479/200000 (13.739%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 27642/200000 (13.821%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 27945/200000 (13.972%) - Rewards: (3, 1, 0, -1)\n",
      "Steps 28108/200000 (14.054%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 28271/200000 (14.136%) - Rewards: (-1, 3, -1, -1)\n",
      "Steps 28454/200000 (14.227%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 28617/200000 (14.308%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 28780/200000 (14.39%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 28983/200000 (14.491%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 29186/200000 (14.593%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 29429/200000 (14.714%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 29592/200000 (14.796%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 29775/200000 (14.888%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 29938/200000 (14.969%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 30121/200000 (15.06%) - Rewards: (-1, 2, 0, -1)\n",
      "Steps 30344/200000 (15.172%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 30527/200000 (15.263%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 30710/200000 (15.355%) - Rewards: (-1, 3, -1, -1)\n",
      "Steps 30913/200000 (15.457%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 31076/200000 (15.538%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 31239/200000 (15.62%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 31402/200000 (15.701%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 31665/200000 (15.832%) - Rewards: (2, 4, -1, -1)\n",
      "Steps 31828/200000 (15.914%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 32031/200000 (16.015%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 32214/200000 (16.107%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 32377/200000 (16.189%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 32560/200000 (16.28%) - Rewards: (-1, 0, -1, 0)\n",
      "Steps 32783/200000 (16.392%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 33026/200000 (16.513%) - Rewards: (2, 3, -1, 0)\n",
      "Steps 33209/200000 (16.605%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 33412/200000 (16.706%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 33575/200000 (16.788%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 33738/200000 (16.869%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 34061/200000 (17.03%) - Rewards: (4, 3, -1, 1)\n",
      "Steps 34224/200000 (17.112%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 34467/200000 (17.233%) - Rewards: (3, 1, 0, -1)\n",
      "Steps 34630/200000 (17.315%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 34813/200000 (17.407%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 35056/200000 (17.528%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 35259/200000 (17.63%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 35442/200000 (17.721%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 35645/200000 (17.822%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 35808/200000 (17.904%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 36031/200000 (18.015%) - Rewards: (-1, -1, 0, 1)\n",
      "Steps 36214/200000 (18.107%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 36397/200000 (18.198%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 36560/200000 (18.28%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 36803/200000 (18.402%) - Rewards: (2, 0, 1, -1)\n",
      "Steps 37046/200000 (18.523%) - Rewards: (4, 2, -1, -1)\n",
      "Steps 37269/200000 (18.635%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 37432/200000 (18.716%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 37655/200000 (18.828%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 37818/200000 (18.909%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 38001/200000 (19.001%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 38224/200000 (19.112%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 38387/200000 (19.194%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 38550/200000 (19.275%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 38713/200000 (19.356%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 38876/200000 (19.438%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 39079/200000 (19.54%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 39302/200000 (19.651%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 39525/200000 (19.762%) - Rewards: (-1, 3, -1, -1)\n",
      "Steps 39688/200000 (19.844%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 39851/200000 (19.925%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 40114/200000 (20.057%) - Rewards: (2, 1, 0, -1)\n",
      "Steps 40277/200000 (20.139%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 40440/200000 (20.22%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 40603/200000 (20.302%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 40926/200000 (20.463%) - Rewards: (2, 6, 0, -1)\n",
      "Steps 41129/200000 (20.564%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 41292/200000 (20.646%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 41475/200000 (20.738%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 41718/200000 (20.859%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 41961/200000 (20.98%) - Rewards: (7, -1, -1, -1)\n",
      "Steps 42144/200000 (21.072%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 42307/200000 (21.154%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 42510/200000 (21.255%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 42793/200000 (21.396%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 42956/200000 (21.478%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 43159/200000 (21.579%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 43342/200000 (21.671%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 43585/200000 (21.793%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 43908/200000 (21.954%) - Rewards: (1, -1, 3, 1)\n",
      "Steps 44131/200000 (22.066%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 44294/200000 (22.147%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 44477/200000 (22.238%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 44640/200000 (22.32%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 44823/200000 (22.412%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 44986/200000 (22.493%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 45169/200000 (22.584%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 45432/200000 (22.716%) - Rewards: (6, -1, -1, -1)\n",
      "Steps 45655/200000 (22.828%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 45858/200000 (22.929%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 46021/200000 (23.011%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 46264/200000 (23.132%) - Rewards: (6, 0, -1, -1)\n",
      "Steps 46427/200000 (23.213%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 46630/200000 (23.315%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 46793/200000 (23.396%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 46956/200000 (23.478%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 47179/200000 (23.59%) - Rewards: (1, 4, -1, -1)\n",
      "Steps 47422/200000 (23.711%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 47585/200000 (23.793%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 47748/200000 (23.874%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 47911/200000 (23.956%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 48094/200000 (24.047%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 48317/200000 (24.159%) - Rewards: (2, -1, -1, 1)\n",
      "Steps 48500/200000 (24.25%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 48663/200000 (24.332%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 48826/200000 (24.413%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 49069/200000 (24.535%) - Rewards: (1, -1, 1, -1)\n",
      "Steps 49232/200000 (24.616%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 49428/200000 (24.714%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 49631/200000 (24.816%) - Rewards: (1, 0, -1, 0)\n",
      "Steps 49814/200000 (24.907%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 49977/200000 (24.988%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 50160/200000 (25.08%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 50363/200000 (25.181%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 50546/200000 (25.273%) - Rewards: (1, -1, -1, 0)\n",
      "Steps 50709/200000 (25.355%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 50872/200000 (25.436%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 51035/200000 (25.517%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 51198/200000 (25.599%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 51361/200000 (25.681%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 51584/200000 (25.792%) - Rewards: (4, 0, -1, -1)\n",
      "Steps 51807/200000 (25.904%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 51970/200000 (25.985%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 52133/200000 (26.066%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 52296/200000 (26.148%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 52479/200000 (26.239%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 52642/200000 (26.321%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 52825/200000 (26.413%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 52988/200000 (26.494%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 53151/200000 (26.576%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 53314/200000 (26.657%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 53497/200000 (26.748%) - Rewards: (3, -1, 0, -1)\n",
      "Steps 53720/200000 (26.86%) - Rewards: (0, 3, -1, -1)\n",
      "Steps 53883/200000 (26.942%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 54046/200000 (27.023%) - Rewards: (-1, 1, -1, 0)\n",
      "Steps 54229/200000 (27.115%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 54412/200000 (27.206%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 54635/200000 (27.317%) - Rewards: (2, 1, 0, -1)\n",
      "Steps 54798/200000 (27.399%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 54961/200000 (27.481%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 55144/200000 (27.572%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 55327/200000 (27.664%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 55490/200000 (27.745%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 55653/200000 (27.826%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 55816/200000 (27.908%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 55979/200000 (27.989%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 56162/200000 (28.081%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 56325/200000 (28.163%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 56508/200000 (28.254%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 56671/200000 (28.336%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 56854/200000 (28.427%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 57017/200000 (28.508%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 57200/200000 (28.6%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 57363/200000 (28.681%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 57526/200000 (28.763%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 57689/200000 (28.845%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 57912/200000 (28.956%) - Rewards: (3, -1, 0, -1)\n",
      "Steps 58075/200000 (29.037%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 58238/200000 (29.119%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 58401/200000 (29.201%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 58584/200000 (29.292%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 58747/200000 (29.374%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 58950/200000 (29.475%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 59113/200000 (29.557%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 59276/200000 (29.638%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 59439/200000 (29.72%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 59602/200000 (29.801%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 59845/200000 (29.923%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 60108/200000 (30.054%) - Rewards: (5, 0, -1, -1)\n",
      "Steps 60291/200000 (30.145%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 60474/200000 (30.237%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 60637/200000 (30.318%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 60900/200000 (30.45%) - Rewards: (5, 1, -1, -1)\n",
      "Steps 61063/200000 (30.532%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 61226/200000 (30.613%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 61389/200000 (30.695%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 61552/200000 (30.776%) - Rewards: (0, -1, 1, -1)\n",
      "Steps 61735/200000 (30.867%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 61958/200000 (30.979%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 62121/200000 (31.061%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 62304/200000 (31.152%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 62507/200000 (31.254%) - Rewards: (2, 1, 0, -1)\n",
      "Steps 62790/200000 (31.395%) - Rewards: (2, 4, -1, -1)\n",
      "Steps 62993/200000 (31.497%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 63176/200000 (31.588%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 63359/200000 (31.68%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 63582/200000 (31.791%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 63765/200000 (31.883%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 64008/200000 (32.004%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 64191/200000 (32.096%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 64354/200000 (32.177%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 64577/200000 (32.288%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 64780/200000 (32.39%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 64943/200000 (32.471%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 65206/200000 (32.603%) - Rewards: (2, 2, 1, -1)\n",
      "Steps 65449/200000 (32.724%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 65652/200000 (32.826%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 65855/200000 (32.927%) - Rewards: (2, 0, 0, -1)\n",
      "Steps 66018/200000 (33.009%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 66281/200000 (33.141%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 66504/200000 (33.252%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 66707/200000 (33.354%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 66910/200000 (33.455%) - Rewards: (0, 4, -1, -1)\n",
      "Steps 67073/200000 (33.537%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 67236/200000 (33.618%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 67479/200000 (33.739%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 67782/200000 (33.891%) - Rewards: (6, 0, -1, 0)\n",
      "Steps 67965/200000 (33.983%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 68328/200000 (34.164%) - Rewards: (6, 4, -1, -1)\n",
      "Steps 68551/200000 (34.276%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 68714/200000 (34.357%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 68937/200000 (34.468%) - Rewards: (1, 1, 0, -1)\n",
      "Steps 69100/200000 (34.55%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 69323/200000 (34.662%) - Rewards: (1, 2, 0, -1)\n",
      "Steps 69486/200000 (34.743%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 69649/200000 (34.825%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 69812/200000 (34.906%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 69995/200000 (34.997%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 70218/200000 (35.109%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 70381/200000 (35.191%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 70564/200000 (35.282%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 70727/200000 (35.363%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 70890/200000 (35.445%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 71173/200000 (35.587%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 71456/200000 (35.728%) - Rewards: (1, 6, -1, -1)\n",
      "Steps 71679/200000 (35.84%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 71962/200000 (35.981%) - Rewards: (1, 4, -1, -1)\n",
      "Steps 72305/200000 (36.152%) - Rewards: (6, 2, -1, -1)\n",
      "Steps 72468/200000 (36.234%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 72691/200000 (36.345%) - Rewards: (1, 3, 0, -1)\n",
      "Steps 72874/200000 (36.437%) - Rewards: (4, 0, 0, -1)\n",
      "Steps 73177/200000 (36.589%) - Rewards: (4, 2, -1, -1)\n",
      "Steps 73420/200000 (36.71%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 73623/200000 (36.812%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 73806/200000 (36.903%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 73969/200000 (36.984%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 74132/200000 (37.066%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 74315/200000 (37.157%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 74478/200000 (37.239%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 74641/200000 (37.321%) - Rewards: (-1, -1, 1, -1)\n",
      "Steps 74804/200000 (37.402%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 74967/200000 (37.483%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 75130/200000 (37.565%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 75573/200000 (37.787%) - Rewards: (8, 8, 0, -1)\n",
      "Steps 75736/200000 (37.868%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 75919/200000 (37.959%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 76262/200000 (38.131%) - Rewards: (7, 2, 0, -1)\n",
      "Steps 76425/200000 (38.212%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 76588/200000 (38.294%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 76751/200000 (38.376%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 76914/200000 (38.457%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 77077/200000 (38.538%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 77340/200000 (38.67%) - Rewards: (3, 3, -1, -1)\n",
      "Steps 77543/200000 (38.771%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 77766/200000 (38.883%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 77929/200000 (38.965%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 78092/200000 (39.046%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 78295/200000 (39.148%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 78498/200000 (39.249%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 78701/200000 (39.35%) - Rewards: (3, -1, -1, 0)\n",
      "Steps 78864/200000 (39.432%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 79067/200000 (39.533%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 79250/200000 (39.625%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 79433/200000 (39.716%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 79596/200000 (39.798%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 79779/200000 (39.889%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 79942/200000 (39.971%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 80265/200000 (40.133%) - Rewards: (7, 3, -1, -1)\n",
      "Steps 80428/200000 (40.214%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 80631/200000 (40.316%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 80794/200000 (40.397%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 80997/200000 (40.498%) - Rewards: (2, 0, 0, -1)\n",
      "Steps 81180/200000 (40.59%) - Rewards: (1, 1, 0, -1)\n",
      "Steps 81363/200000 (40.681%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 81646/200000 (40.823%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 81809/200000 (40.904%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 81972/200000 (40.986%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 82275/200000 (41.137%) - Rewards: (7, 0, 0, -1)\n",
      "Steps 82458/200000 (41.229%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 82661/200000 (41.331%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 82824/200000 (41.412%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 83027/200000 (41.514%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 83190/200000 (41.595%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 83373/200000 (41.686%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 83556/200000 (41.778%) - Rewards: (3, 0, 0, -1)\n",
      "Steps 83739/200000 (41.869%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 83942/200000 (41.971%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 84125/200000 (42.062%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 84288/200000 (42.144%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 84451/200000 (42.225%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 84614/200000 (42.307%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 84797/200000 (42.398%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 85020/200000 (42.51%) - Rewards: (1, 2, 0, -1)\n",
      "Steps 85183/200000 (42.591%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 85346/200000 (42.673%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 85529/200000 (42.764%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 85752/200000 (42.876%) - Rewards: (-1, 3, -1, 0)\n",
      "Steps 85935/200000 (42.967%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 86118/200000 (43.059%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 86281/200000 (43.14%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 86464/200000 (43.232%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 86647/200000 (43.323%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 86810/200000 (43.405%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 86973/200000 (43.486%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 87136/200000 (43.568%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 87299/200000 (43.65%) - Rewards: (0, -1, 1, -1)\n",
      "Steps 87462/200000 (43.731%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 87625/200000 (43.812%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 87788/200000 (43.894%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 87951/200000 (43.976%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 88174/200000 (44.087%) - Rewards: (0, 1, -1, 0)\n",
      "Steps 88357/200000 (44.178%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 88540/200000 (44.27%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 88803/200000 (44.401%) - Rewards: (4, 0, 0, -1)\n",
      "Steps 88966/200000 (44.483%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 89189/200000 (44.594%) - Rewards: (2, 1, 0, -1)\n",
      "Steps 89472/200000 (44.736%) - Rewards: (1, 4, -1, -1)\n",
      "Steps 89635/200000 (44.817%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 89798/200000 (44.899%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 89961/200000 (44.98%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 90224/200000 (45.112%) - Rewards: (1, 3, 1, 0)\n",
      "Steps 90487/200000 (45.243%) - Rewards: (5, 0, -1, 1)\n",
      "Steps 90750/200000 (45.375%) - Rewards: (3, 1, 1, -1)\n",
      "Steps 90953/200000 (45.476%) - Rewards: (3, -1, 0, 0)\n",
      "Steps 91116/200000 (45.558%) - Rewards: (-1, 0, -1, 0)\n",
      "Steps 91299/200000 (45.649%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 91502/200000 (45.751%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 91665/200000 (45.832%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 91828/200000 (45.914%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 91991/200000 (45.995%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 92154/200000 (46.077%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 92417/200000 (46.209%) - Rewards: (2, 3, -1, -1)\n",
      "Steps 92640/200000 (46.32%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 92823/200000 (46.411%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 92986/200000 (46.493%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 93149/200000 (46.575%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 93312/200000 (46.656%) - Rewards: (-1, -1, 1, -1)\n",
      "Steps 93515/200000 (46.758%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 93678/200000 (46.839%) - Rewards: (-1, -1, 3, -1)\n",
      "Steps 93841/200000 (46.92%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 94144/200000 (47.072%) - Rewards: (6, 1, 0, -1)\n",
      "Steps 94327/200000 (47.163%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 94650/200000 (47.325%) - Rewards: (6, 2, -1, -1)\n",
      "Steps 94833/200000 (47.416%) - Rewards: (0, -1, 2, -1)\n",
      "Steps 95016/200000 (47.508%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 95179/200000 (47.59%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 95462/200000 (47.731%) - Rewards: (6, 1, 1, -1)\n",
      "Steps 95645/200000 (47.822%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 95808/200000 (47.904%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 95991/200000 (47.995%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 96154/200000 (48.077%) - Rewards: (0, -1, 1, -1)\n",
      "Steps 96317/200000 (48.158%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 96540/200000 (48.27%) - Rewards: (-1, 1, 0, -1)\n",
      "Steps 96943/200000 (48.471%) - Rewards: (6, 4, 1, -1)\n",
      "Steps 97206/200000 (48.603%) - Rewards: (1, 4, 0, -1)\n",
      "Steps 97449/200000 (48.724%) - Rewards: (4, -1, 0, -1)\n",
      "Steps 97612/200000 (48.806%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 97775/200000 (48.888%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 97938/200000 (48.969%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 98121/200000 (49.061%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 98284/200000 (49.142%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 98467/200000 (49.233%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 98670/200000 (49.335%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 98853/200000 (49.427%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 99036/200000 (49.518%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 99259/200000 (49.63%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 99442/200000 (49.721%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 99645/200000 (49.822%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 99808/200000 (49.904%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 100051/200000 (50.026%) - Rewards: (5, -1, -1, -1)\n",
      "Steps 100214/200000 (50.107%) - Rewards: (-1, -1, 0, -1)\n",
      "Steps 100377/200000 (50.189%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 100600/200000 (50.3%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 100763/200000 (50.382%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 100926/200000 (50.463%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 101089/200000 (50.545%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 101272/200000 (50.636%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 101435/200000 (50.718%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 101678/200000 (50.839%) - Rewards: (5, -1, -1, -1)\n",
      "Steps 101861/200000 (50.931%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 102104/200000 (51.052%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 102367/200000 (51.184%) - Rewards: (6, 0, 0, -1)\n",
      "Steps 102550/200000 (51.275%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 102713/200000 (51.357%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 102956/200000 (51.478%) - Rewards: (2, -1, 1, -1)\n",
      "Steps 103119/200000 (51.559%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 103282/200000 (51.641%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 103485/200000 (51.742%) - Rewards: (5, 0, -1, -1)\n",
      "Steps 103668/200000 (51.834%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 103911/200000 (51.956%) - Rewards: (4, 0, -1, -1)\n",
      "Steps 104074/200000 (52.037%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 104237/200000 (52.118%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 104400/200000 (52.2%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 104563/200000 (52.282%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 104746/200000 (52.373%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 104929/200000 (52.465%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 105092/200000 (52.546%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 105275/200000 (52.638%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 105498/200000 (52.749%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 105661/200000 (52.831%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 105844/200000 (52.922%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 106047/200000 (53.023%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 106210/200000 (53.105%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 106373/200000 (53.187%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 106536/200000 (53.268%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 106739/200000 (53.37%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 106902/200000 (53.451%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 107065/200000 (53.533%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 107268/200000 (53.634%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 107431/200000 (53.716%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 107594/200000 (53.797%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 107777/200000 (53.888%) - Rewards: (5, -1, -1, -1)\n",
      "Steps 107940/200000 (53.97%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 108103/200000 (54.051%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 108266/200000 (54.133%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 108449/200000 (54.224%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 108632/200000 (54.316%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 108835/200000 (54.417%) - Rewards: (5, -1, -1, -1)\n",
      "Steps 108998/200000 (54.499%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 109161/200000 (54.581%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 109324/200000 (54.662%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 109487/200000 (54.743%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 109710/200000 (54.855%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 109873/200000 (54.937%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 110036/200000 (55.018%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 110239/200000 (55.12%) - Rewards: (4, 0, -1, -1)\n",
      "Steps 110422/200000 (55.211%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 110585/200000 (55.292%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 110808/200000 (55.404%) - Rewards: (6, 0, -1, -1)\n",
      "Steps 110971/200000 (55.486%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 111134/200000 (55.567%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 111297/200000 (55.648%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 111500/200000 (55.75%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 111663/200000 (55.831%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 111846/200000 (55.923%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 112029/200000 (56.014%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 112212/200000 (56.106%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 112375/200000 (56.188%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 112538/200000 (56.269%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 112721/200000 (56.361%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 112924/200000 (56.462%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 113107/200000 (56.553%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 113490/200000 (56.745%) - Rewards: (8, 5, -1, -1)\n",
      "Steps 113753/200000 (56.876%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 113916/200000 (56.958%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 114099/200000 (57.049%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 114262/200000 (57.131%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 114425/200000 (57.212%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 114688/200000 (57.344%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 114871/200000 (57.435%) - Rewards: (1, -1, 1, -1)\n",
      "Steps 115034/200000 (57.517%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 115217/200000 (57.608%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 115420/200000 (57.71%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 115683/200000 (57.842%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 115866/200000 (57.933%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 116089/200000 (58.044%) - Rewards: (2, 2, 0, -1)\n",
      "Steps 116272/200000 (58.136%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 116515/200000 (58.257%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 116698/200000 (58.349%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 116901/200000 (58.451%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 117124/200000 (58.562%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 117367/200000 (58.684%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 117550/200000 (58.775%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 117793/200000 (58.896%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 117996/200000 (58.998%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 118159/200000 (59.079%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 118342/200000 (59.171%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 118545/200000 (59.272%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 118708/200000 (59.354%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 118871/200000 (59.435%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 119034/200000 (59.517%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 119197/200000 (59.599%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 119480/200000 (59.74%) - Rewards: (3, 2, 0, 0)\n",
      "Steps 119643/200000 (59.822%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 119826/200000 (59.913%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 119989/200000 (59.994%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 120212/200000 (60.106%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 120415/200000 (60.208%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 120618/200000 (60.309%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 120781/200000 (60.391%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 120944/200000 (60.472%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 121207/200000 (60.603%) - Rewards: (5, 1, 0, -1)\n",
      "Steps 121370/200000 (60.685%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 121593/200000 (60.796%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 121756/200000 (60.878%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 121919/200000 (60.959%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 122142/200000 (61.071%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 122305/200000 (61.152%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 122548/200000 (61.274%) - Rewards: (6, -1, -1, -1)\n",
      "Steps 122751/200000 (61.376%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 122954/200000 (61.477%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 123117/200000 (61.559%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 123300/200000 (61.65%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 123463/200000 (61.731%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 123626/200000 (61.813%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 123829/200000 (61.914%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 124012/200000 (62.006%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 124215/200000 (62.108%) - Rewards: (2, 2, -1, -1)\n",
      "Steps 124378/200000 (62.189%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 124541/200000 (62.27%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 124704/200000 (62.352%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 124867/200000 (62.433%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 125030/200000 (62.515%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 125253/200000 (62.626%) - Rewards: (5, -1, -1, -1)\n",
      "Steps 125476/200000 (62.738%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 125779/200000 (62.889%) - Rewards: (3, 5, -1, -1)\n",
      "Steps 125942/200000 (62.971%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 126105/200000 (63.053%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 126268/200000 (63.134%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 126431/200000 (63.216%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 126634/200000 (63.317%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 126797/200000 (63.398%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 127000/200000 (63.5%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 127163/200000 (63.582%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 127326/200000 (63.663%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 127509/200000 (63.755%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 127752/200000 (63.876%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 127975/200000 (63.987%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 128178/200000 (64.089%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 128421/200000 (64.211%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 128624/200000 (64.312%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 128787/200000 (64.394%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 128950/200000 (64.475%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 129113/200000 (64.556%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 129276/200000 (64.638%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 129459/200000 (64.73%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 129622/200000 (64.811%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 129785/200000 (64.892%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 129968/200000 (64.984%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 130131/200000 (65.066%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 130314/200000 (65.157%) - Rewards: (1, -1, 1, -1)\n",
      "Steps 130497/200000 (65.248%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 130660/200000 (65.33%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 130823/200000 (65.412%) - Rewards: (-1, 0, 0, -1)\n",
      "Steps 130986/200000 (65.493%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 131189/200000 (65.594%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 131372/200000 (65.686%) - Rewards: (2, -1, 1, -1)\n",
      "Steps 131535/200000 (65.767%) - Rewards: (0, -1, 1, -1)\n",
      "Steps 131718/200000 (65.859%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 131901/200000 (65.951%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 132064/200000 (66.032%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 132227/200000 (66.114%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 132450/200000 (66.225%) - Rewards: (3, 1, 0, -1)\n",
      "Steps 132633/200000 (66.317%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 132816/200000 (66.408%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 132979/200000 (66.49%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 133142/200000 (66.571%) - Rewards: (0, 3, -1, -1)\n",
      "Steps 133345/200000 (66.672%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 133508/200000 (66.754%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 133671/200000 (66.835%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 133994/200000 (66.997%) - Rewards: (10, 0, -1, -1)\n",
      "Steps 134157/200000 (67.078%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 134380/200000 (67.19%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 134543/200000 (67.271%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 134706/200000 (67.353%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 134869/200000 (67.434%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 135052/200000 (67.526%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 135255/200000 (67.627%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 135458/200000 (67.729%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 135741/200000 (67.871%) - Rewards: (5, -1, -1, 0)\n",
      "Steps 136004/200000 (68.002%) - Rewards: (3, 0, 1, 0)\n",
      "Steps 136167/200000 (68.084%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 136330/200000 (68.165%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 136493/200000 (68.246%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 136656/200000 (68.328%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 136839/200000 (68.419%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 137002/200000 (68.501%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 137185/200000 (68.593%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 137348/200000 (68.674%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 137511/200000 (68.755%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 137674/200000 (68.837%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 137837/200000 (68.919%) - Rewards: (0, -1, 0, 0)\n",
      "Steps 138000/200000 (69.0%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 138163/200000 (69.081%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 138326/200000 (69.163%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 138489/200000 (69.245%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 138692/200000 (69.346%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 138875/200000 (69.438%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 139058/200000 (69.529%) - Rewards: (0, -1, 2, 0)\n",
      "Steps 139221/200000 (69.611%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 139384/200000 (69.692%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 139567/200000 (69.784%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 139850/200000 (69.925%) - Rewards: (1, 4, -1, 0)\n",
      "Steps 140013/200000 (70.007%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 140176/200000 (70.088%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 140359/200000 (70.179%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 140522/200000 (70.261%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 140685/200000 (70.343%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 140868/200000 (70.434%) - Rewards: (1, 0, 0, -1)\n",
      "Steps 141031/200000 (70.516%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 141214/200000 (70.607%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 141457/200000 (70.729%) - Rewards: (1, 1, 1, -1)\n",
      "Steps 141620/200000 (70.81%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 141803/200000 (70.901%) - Rewards: (3, -1, -1, 0)\n",
      "Steps 141966/200000 (70.983%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 142129/200000 (71.064%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 142292/200000 (71.146%) - Rewards: (0, 0, 1, -1)\n",
      "Steps 142475/200000 (71.237%) - Rewards: (0, -1, 1, -1)\n",
      "Steps 142678/200000 (71.339%) - Rewards: (1, -1, -1, 0)\n",
      "Steps 142841/200000 (71.421%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 143004/200000 (71.502%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 143167/200000 (71.584%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 143330/200000 (71.665%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 143553/200000 (71.776%) - Rewards: (4, -1, -1, 0)\n",
      "Steps 143716/200000 (71.858%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 143899/200000 (71.95%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 144062/200000 (72.031%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 144265/200000 (72.132%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 144428/200000 (72.214%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 144591/200000 (72.296%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 144794/200000 (72.397%) - Rewards: (0, 2, 0, -1)\n",
      "Steps 144997/200000 (72.498%) - Rewards: (3, 1, 0, -1)\n",
      "Steps 145160/200000 (72.58%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 145323/200000 (72.662%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 145526/200000 (72.763%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 145689/200000 (72.844%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 145872/200000 (72.936%) - Rewards: (3, -1, 0, 0)\n",
      "Steps 146055/200000 (73.028%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 146238/200000 (73.119%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 146421/200000 (73.21%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 146584/200000 (73.292%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 146767/200000 (73.383%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 146950/200000 (73.475%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 147193/200000 (73.596%) - Rewards: (2, -1, -1, 0)\n",
      "Steps 147396/200000 (73.698%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 147599/200000 (73.799%) - Rewards: (0, -1, 0, 0)\n",
      "Steps 147762/200000 (73.881%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 147965/200000 (73.983%) - Rewards: (2, -1, 0, 0)\n",
      "Steps 148188/200000 (74.094%) - Rewards: (1, 2, 0, -1)\n",
      "Steps 148371/200000 (74.186%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 148554/200000 (74.277%) - Rewards: (-1, 1, -1, 1)\n",
      "Steps 148737/200000 (74.368%) - Rewards: (2, -1, -1, 0)\n",
      "Steps 148940/200000 (74.47%) - Rewards: (0, -1, 1, 0)\n",
      "Steps 149143/200000 (74.572%) - Rewards: (0, 0, -1, 1)\n",
      "Steps 149306/200000 (74.653%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 149469/200000 (74.734%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 149712/200000 (74.856%) - Rewards: (0, 3, -1, -1)\n",
      "Steps 149915/200000 (74.957%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 150078/200000 (75.039%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 150241/200000 (75.121%) - Rewards: (0, -1, 1, 0)\n",
      "Steps 150424/200000 (75.212%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 150587/200000 (75.294%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 150770/200000 (75.385%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 150933/200000 (75.466%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 151096/200000 (75.548%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 151399/200000 (75.7%) - Rewards: (4, 3, 0, -1)\n",
      "Steps 151582/200000 (75.791%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 151765/200000 (75.882%) - Rewards: (0, -1, 1, 0)\n",
      "Steps 151948/200000 (75.974%) - Rewards: (-1, 0, 1, -1)\n",
      "Steps 152171/200000 (76.085%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 152354/200000 (76.177%) - Rewards: (0, 0, -1, 0)\n",
      "Steps 152537/200000 (76.268%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 152700/200000 (76.35%) - Rewards: (2, 0, -1, 0)\n",
      "Steps 152863/200000 (76.431%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 153026/200000 (76.513%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 153269/200000 (76.635%) - Rewards: (1, 0, -1, 1)\n",
      "Steps 153432/200000 (76.716%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 153595/200000 (76.797%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 153758/200000 (76.879%) - Rewards: (4, 0, -1, -1)\n",
      "Steps 153941/200000 (76.971%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 154124/200000 (77.062%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 154287/200000 (77.144%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 154470/200000 (77.235%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 154693/200000 (77.346%) - Rewards: (0, 1, -1, 0)\n",
      "Steps 154916/200000 (77.458%) - Rewards: (2, 0, 0, -1)\n",
      "Steps 155099/200000 (77.55%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 155262/200000 (77.631%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 155425/200000 (77.712%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 155728/200000 (77.864%) - Rewards: (4, 2, -1, 0)\n",
      "Steps 155911/200000 (77.956%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 156074/200000 (78.037%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 156257/200000 (78.129%) - Rewards: (-1, 0, 1, -1)\n",
      "Steps 156480/200000 (78.24%) - Rewards: (1, 1, -1, 0)\n",
      "Steps 156643/200000 (78.322%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 156826/200000 (78.413%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 157009/200000 (78.504%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 157192/200000 (78.596%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 157435/200000 (78.718%) - Rewards: (1, 2, -1, 0)\n",
      "Steps 157598/200000 (78.799%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 157761/200000 (78.88%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 158044/200000 (79.022%) - Rewards: (2, 3, 1, -1)\n",
      "Steps 158267/200000 (79.133%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 158430/200000 (79.215%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 158633/200000 (79.317%) - Rewards: (-1, 1, 0, -1)\n",
      "Steps 158816/200000 (79.408%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 159039/200000 (79.519%) - Rewards: (1, 0, -1, 0)\n",
      "Steps 159262/200000 (79.631%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 159445/200000 (79.722%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 159608/200000 (79.804%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 159771/200000 (79.885%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 160054/200000 (80.027%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 160237/200000 (80.118%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 160440/200000 (80.22%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 160683/200000 (80.341%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 160846/200000 (80.423%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 161009/200000 (80.505%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 161172/200000 (80.586%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 161335/200000 (80.668%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 161498/200000 (80.749%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 161661/200000 (80.831%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 161844/200000 (80.922%) - Rewards: (-1, 0, -1, 0)\n",
      "Steps 162007/200000 (81.003%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 162170/200000 (81.085%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 162453/200000 (81.227%) - Rewards: (3, 2, -1, 0)\n",
      "Steps 162656/200000 (81.328%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 162839/200000 (81.419%) - Rewards: (1, 1, 0, -1)\n",
      "Steps 163102/200000 (81.551%) - Rewards: (5, -1, 0, -1)\n",
      "Steps 163305/200000 (81.652%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 163628/200000 (81.814%) - Rewards: (6, 1, -1, 0)\n",
      "Steps 163871/200000 (81.936%) - Rewards: (3, 2, 0, -1)\n",
      "Steps 164094/200000 (82.047%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 164257/200000 (82.129%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 164640/200000 (82.32%) - Rewards: (9, 1, 0, -1)\n",
      "Steps 164803/200000 (82.401%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 165026/200000 (82.513%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 165309/200000 (82.654%) - Rewards: (4, 2, -1, -1)\n",
      "Steps 165492/200000 (82.746%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 165675/200000 (82.837%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 165898/200000 (82.949%) - Rewards: (1, 2, -1, -1)\n",
      "Steps 166101/200000 (83.05%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 166324/200000 (83.162%) - Rewards: (4, 0, 0, -1)\n",
      "Steps 166567/200000 (83.284%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 166730/200000 (83.365%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 166893/200000 (83.447%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 167056/200000 (83.528%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 167319/200000 (83.659%) - Rewards: (3, 2, -1, -1)\n",
      "Steps 167502/200000 (83.751%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 167685/200000 (83.843%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 167848/200000 (83.924%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 168011/200000 (84.005%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 168194/200000 (84.097%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 168457/200000 (84.228%) - Rewards: (3, 0, -1, 0)\n",
      "Steps 168720/200000 (84.36%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 168883/200000 (84.442%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 169046/200000 (84.523%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 169249/200000 (84.624%) - Rewards: (1, -1, 1, -1)\n",
      "Steps 169412/200000 (84.706%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 169595/200000 (84.797%) - Rewards: (0, 1, 0, -1)\n",
      "Steps 169758/200000 (84.879%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 170041/200000 (85.02%) - Rewards: (4, 3, -1, -1)\n",
      "Steps 170204/200000 (85.102%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 170407/200000 (85.204%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 170570/200000 (85.285%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 170873/200000 (85.437%) - Rewards: (6, 2, -1, -1)\n",
      "Steps 171076/200000 (85.538%) - Rewards: (-1, 1, 0, -1)\n",
      "Steps 171239/200000 (85.62%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 171462/200000 (85.731%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 171625/200000 (85.812%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 171928/200000 (85.964%) - Rewards: (5, 1, -1, 0)\n",
      "Steps 172111/200000 (86.055%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 172354/200000 (86.177%) - Rewards: (4, 1, -1, -1)\n",
      "Steps 172537/200000 (86.269%) - Rewards: (2, 0, 0, -1)\n",
      "Steps 172700/200000 (86.35%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 172863/200000 (86.431%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 173086/200000 (86.543%) - Rewards: (-1, 0, 0, 0)\n",
      "Steps 173289/200000 (86.645%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 173472/200000 (86.736%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 173635/200000 (86.818%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 173798/200000 (86.899%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 174061/200000 (87.031%) - Rewards: (1, 1, 1, -1)\n",
      "Steps 174224/200000 (87.112%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 174507/200000 (87.253%) - Rewards: (2, 1, 1, -1)\n",
      "Steps 174730/200000 (87.365%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 174913/200000 (87.457%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 175096/200000 (87.548%) - Rewards: (0, 0, 0, -1)\n",
      "Steps 175319/200000 (87.66%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 175482/200000 (87.741%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 175685/200000 (87.843%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 175848/200000 (87.924%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 176031/200000 (88.016%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 176194/200000 (88.097%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 176537/200000 (88.269%) - Rewards: (6, 2, -1, -1)\n",
      "Steps 176800/200000 (88.4%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 176963/200000 (88.481%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 177126/200000 (88.563%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 177289/200000 (88.645%) - Rewards: (1, -1, 0, -1)\n",
      "Steps 177472/200000 (88.736%) - Rewards: (3, -1, -1, -1)\n",
      "Steps 177715/200000 (88.858%) - Rewards: (1, 2, 0, -1)\n",
      "Steps 177878/200000 (88.939%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 178061/200000 (89.031%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 178284/200000 (89.142%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 178487/200000 (89.243%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 178650/200000 (89.325%) - Rewards: (0, -1, 0, -1)\n",
      "Steps 178833/200000 (89.416%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 179076/200000 (89.538%) - Rewards: (4, -1, 0, -1)\n",
      "Steps 179279/200000 (89.639%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 179482/200000 (89.741%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 179645/200000 (89.823%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 179968/200000 (89.984%) - Rewards: (4, 4, 0, -1)\n",
      "Steps 180211/200000 (90.106%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 180554/200000 (90.277%) - Rewards: (8, 0, -1, -1)\n",
      "Steps 180757/200000 (90.378%) - Rewards: (1, -1, 1, -1)\n",
      "Steps 181000/200000 (90.5%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 181183/200000 (90.591%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 181406/200000 (90.703%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 181629/200000 (90.814%) - Rewards: (4, -1, 1, -1)\n",
      "Steps 181852/200000 (90.926%) - Rewards: (1, -1, 1, 0)\n",
      "Steps 182015/200000 (91.007%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 182178/200000 (91.089%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 182421/200000 (91.211%) - Rewards: (6, -1, -1, -1)\n",
      "Steps 182604/200000 (91.302%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 182847/200000 (91.424%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 183050/200000 (91.525%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 183253/200000 (91.626%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 183416/200000 (91.708%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 183579/200000 (91.79%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 183802/200000 (91.901%) - Rewards: (1, 0, 0, 0)\n",
      "Steps 183985/200000 (91.992%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 184188/200000 (92.094%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 184371/200000 (92.186%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 184594/200000 (92.297%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 184777/200000 (92.388%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 184940/200000 (92.47%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 185123/200000 (92.561%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 185286/200000 (92.643%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 185449/200000 (92.724%) - Rewards: (-1, 1, -1, -1)\n",
      "Steps 185612/200000 (92.806%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 185775/200000 (92.888%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 185978/200000 (92.989%) - Rewards: (-1, 0, -1, 0)\n",
      "Steps 186181/200000 (93.09%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 186364/200000 (93.182%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 186607/200000 (93.303%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 186850/200000 (93.425%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 187033/200000 (93.517%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 187236/200000 (93.618%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 187399/200000 (93.7%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 187602/200000 (93.801%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 187845/200000 (93.922%) - Rewards: (4, -1, -1, 0)\n",
      "Steps 188008/200000 (94.004%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 188171/200000 (94.085%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 188354/200000 (94.177%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 188597/200000 (94.298%) - Rewards: (4, -1, 0, -1)\n",
      "Steps 188760/200000 (94.38%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 188923/200000 (94.462%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 189126/200000 (94.563%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 189309/200000 (94.654%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 189492/200000 (94.746%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 189795/200000 (94.898%) - Rewards: (0, 3, 2, -1)\n",
      "Steps 189958/200000 (94.979%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 190141/200000 (95.07%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 190524/200000 (95.262%) - Rewards: (8, 1, 1, -1)\n",
      "Steps 190807/200000 (95.403%) - Rewards: (8, 1, -1, -1)\n",
      "Steps 191010/200000 (95.505%) - Rewards: (2, 0, -1, -1)\n",
      "Steps 191173/200000 (95.587%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 191356/200000 (95.678%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 191519/200000 (95.76%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 191802/200000 (95.901%) - Rewards: (3, 3, -1, -1)\n",
      "Steps 192045/200000 (96.022%) - Rewards: (3, 1, -1, -1)\n",
      "Steps 192228/200000 (96.114%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 192411/200000 (96.206%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 192694/200000 (96.347%) - Rewards: (3, 0, 0, -1)\n",
      "Steps 192957/200000 (96.478%) - Rewards: (5, 1, -1, -1)\n",
      "Steps 193120/200000 (96.56%) - Rewards: (-1, -1, -1, 0)\n",
      "Steps 193283/200000 (96.642%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 193446/200000 (96.723%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 193689/200000 (96.844%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 193912/200000 (96.956%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 194095/200000 (97.047%) - Rewards: (0, 1, -1, -1)\n",
      "Steps 194278/200000 (97.139%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 194501/200000 (97.25%) - Rewards: (3, 0, -1, -1)\n",
      "Steps 194684/200000 (97.342%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 194927/200000 (97.463%) - Rewards: (4, -1, -1, -1)\n",
      "Steps 195110/200000 (97.555%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 195333/200000 (97.666%) - Rewards: (-1, 2, 0, -1)\n",
      "Steps 195576/200000 (97.788%) - Rewards: (2, 3, -1, -1)\n",
      "Steps 195739/200000 (97.87%) - Rewards: (1, -1, -1, 0)\n",
      "Steps 196022/200000 (98.011%) - Rewards: (1, 4, -1, -1)\n",
      "Steps 196205/200000 (98.103%) - Rewards: (2, -1, 0, -1)\n",
      "Steps 196368/200000 (98.184%) - Rewards: (-1, 0, -1, -1)\n",
      "Steps 196551/200000 (98.276%) - Rewards: (0, -1, -1, -1)\n",
      "Steps 196794/200000 (98.397%) - Rewards: (-1, 2, -1, 0)\n",
      "Steps 196957/200000 (98.478%) - Rewards: (-1, -1, -1, -1)\n",
      "Steps 197180/200000 (98.59%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 197383/200000 (98.692%) - Rewards: (1, 1, -1, -1)\n",
      "Steps 197606/200000 (98.803%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 197789/200000 (98.894%) - Rewards: (1, 0, -1, -1)\n",
      "Steps 197972/200000 (98.986%) - Rewards: (2, -1, -1, -1)\n",
      "Steps 198175/200000 (99.087%) - Rewards: (0, -1, -1, 0)\n",
      "Steps 198378/200000 (99.189%) - Rewards: (0, 2, -1, -1)\n",
      "Steps 198561/200000 (99.281%) - Rewards: (0, 0, -1, -1)\n",
      "Steps 198744/200000 (99.372%) - Rewards: (1, -1, -1, -1)\n",
      "Steps 199027/200000 (99.513%) - Rewards: (1, 3, -1, -1)\n",
      "Steps 199270/200000 (99.635%) - Rewards: (0, 4, -1, 0)\n",
      "Steps 199453/200000 (99.727%) - Rewards: (-1, 2, -1, -1)\n",
      "Steps 199756/200000 (99.878%) - Rewards: (2, 3, -1, -1)\n",
      "Steps 199979/200000 (99.989%) - Rewards: (2, 1, -1, -1)\n",
      "Steps 200202/200000 (100.101%) - Rewards: (4, -1, -1, -1)\n",
      "Entraînement terminé!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialisation de l'environnement et de chaque agent\n",
    "env = knights_archers_zombies_v10.env()\n",
    "env = aec_to_parallel(env)\n",
    "\n",
    "env.reset()\n",
    "agents = env.agents  # Obtenir la liste des agents après reset\n",
    "num_agents = len(agents)\n",
    "state_dims = env.observation_space(agents[0]).shape[0] * 5\n",
    "action_dims = env.action_space(agents[0]).n\n",
    "\n",
    "# Hyperparamètres\n",
    "epsilon = 0.1\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "gamma = 0.99\n",
    "lr = 0.0001\n",
    "batch_size = 128\n",
    "buffer_capacity = 1024\n",
    "target_update_freq = 100\n",
    "num_episodes = 1_000_000 # Tres grand pour un arret via le nombre de pas  TODO\n",
    "reward_penalty = 1\n",
    "# Initialisation des réseaux Q et des buffers pour chaque agent\n",
    "q_networks = {agent: QNetwork(state_dims, action_dims) for agent in agents}\n",
    "target_networks = {agent: QNetwork(state_dims, action_dims) for agent in agents}\n",
    "optimizers = {agent: optim.Adam(q_networks[agent].parameters(), lr=lr) for agent in agents}\n",
    "buffers = {agent: ReplayBuffer(buffer_capacity) for agent in agents}\n",
    "\n",
    "# Gestion des agents inactifs\n",
    "black_obs = {agent: np.zeros_like(env.observation_space(agent).low) for agent in env.agents}\n",
    "black_rewards = {agent: 0 for agent in env.agents}\n",
    "black_dones = {agent: True for agent in env.agents}\n",
    "\n",
    "# Nombre de pas maximum par épisode\n",
    "max_steps = 500\n",
    "nb_steps = 0\n",
    "total_nb_steps = 0\n",
    "max_total_steps = 200_000\n",
    "\n",
    "# Synchronisation initiale des réseaux cibles\n",
    "for agent in agents:\n",
    "    target_networks[agent].load_state_dict(q_networks[agent].state_dict())\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for episode in range(num_episodes):\n",
    "   # obs,_ = env.reset()\n",
    "   # state = {agent: env.observe(agent) for agent in agents}  # Initialiser l'état pour chaque agent\n",
    "    state,_ = env.reset()\n",
    "    done = {agent: False for agent in agents}\n",
    "    episode_reward = {agent: 0 for agent in agents}\n",
    "\n",
    "    while not (all(done.values()) or nb_steps >= max_steps):\n",
    "        actions = {}\n",
    "        \n",
    "        # Sélection d'actions pour chaque agent\n",
    "        for agent in agents:\n",
    "            if not done[agent]:\n",
    "                action = select_action(state[agent], q_networks[agent], epsilon, action_dims)\n",
    "                \n",
    "                # Vérification de l'action\n",
    "                assert 0 <= action < action_dims, f\"Action {action} pour {agent} n'est pas dans l'espace d'actions [0, {action_dims - 1}]\"\n",
    "                actions[agent] = action\n",
    "                #print(f\"Agent {agent} a choisi l'action {action}\")\n",
    "\n",
    "        # Environnement procède aux actions\n",
    "        #print(actions)\n",
    "        next_state, rewards, dones, _ ,_= env.step(actions)\n",
    "\n",
    "        dones = {**black_dones, **dones}\n",
    "        rewards = {**black_rewards, **rewards}\n",
    "        next_state = {**black_obs, **next_state}\n",
    "        #print(rewards)\n",
    "        \n",
    "        # mean_global_reward = np.mean(list(rewards.values())) #TODO Maybe ?\n",
    "\n",
    "        # Enregistrement de chaque expérience dans le buffer\n",
    "        for agent in agents:\n",
    "            if not done[agent]:\n",
    "                if(dones[agent]):\n",
    "                    rewards[agent]-= reward_penalty\n",
    "\n",
    "                # rewards[agent] += mean_global_reward # Ajout de la récompense moyenne globale \n",
    "                \n",
    "                buffers[agent].push(state[agent], actions[agent], rewards[agent], next_state[agent], dones[agent])\n",
    "                episode_reward[agent] += rewards[agent]\n",
    "\n",
    "            # Mise à jour des états et terminaux\n",
    "            \n",
    "            done[agent] = dones[agent]\n",
    "        \n",
    "        # Mise à jour des états pour le prochain pas de temps\n",
    "        for agent in agents:\n",
    "            if not done[agent]:\n",
    "                state[agent] = next_state[agent]  # Mettre à jour l'état pour chaque agent\n",
    "\n",
    "        # Apprentissage pour chaque agent\n",
    "        for agent in agents:\n",
    "            if len(buffers[agent]) >= batch_size and not done[agent]:\n",
    "                # Extraction d'un mini-lot d'expériences\n",
    "                batch = buffers[agent].sample(batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "                # Conversion des expériences en tenseurs\n",
    "                states = torch.FloatTensor([s.flatten() for s in states])\n",
    "                next_states = torch.FloatTensor([ns.flatten() for ns in next_states])\n",
    "                actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "                rewards = torch.FloatTensor(rewards)\n",
    "                dones = torch.FloatTensor(dones)\n",
    "\n",
    "                # Calcul des valeurs Q cibles\n",
    "                with torch.no_grad():\n",
    "                    target_values = rewards + gamma * torch.max(target_networks[agent](next_states), dim=1).values * (1 - dones)\n",
    "\n",
    "                # Calcul des valeurs Q prédites\n",
    "                q_values = q_networks[agent](states)\n",
    "                q_values = q_values.gather(1, actions)\n",
    "\n",
    "                # Calcul de la perte\n",
    "                loss = nn.MSELoss()(q_values, target_values.unsqueeze(1))\n",
    "\n",
    "                # Mise à jour du réseau\n",
    "                optimizers[agent].zero_grad()\n",
    "                loss.backward()\n",
    "                optimizers[agent].step()\n",
    "\n",
    "\n",
    "        # Mise à jour des réseaux cibles\n",
    "        if episode % target_update_freq == 0:\n",
    "            for agent in agents:\n",
    "                target_networks[agent].load_state_dict(q_networks[agent].state_dict())\n",
    "\n",
    "        nb_steps += 1\n",
    "        total_nb_steps += 1\n",
    "\n",
    "\n",
    "\n",
    "    nb_steps = 0\n",
    "    # Décroissance de epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "    print(f\"Steps {total_nb_steps}/{max_total_steps} ({round((total_nb_steps/max_total_steps)*100,3)}%) - Rewards: {tuple(episode_reward.values())}\")\n",
    "\n",
    "    if total_nb_steps >= max_total_steps:\n",
    "        break\n",
    "\n",
    "print(\"Entraînement terminé!\")\n",
    "\n",
    "# Sauvegarde des réseaux Q\n",
    "for agent in agents:\n",
    "    torch.save(q_networks[agent].state_dict(), f\"q_network_agent_{agent}_knights_archers_zombies.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 2/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 3/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 4/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 5/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 6/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 7/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 8/100 - Rewards: {'archer_0': 0, 'archer_1': 2, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 9/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 10/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 11/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 12/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 13/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 14/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 15/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 16/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 17/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 18/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 19/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 20/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 21/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 22/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 23/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 24/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 25/100 - Rewards: {'archer_0': 1, 'archer_1': 5, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 26/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 27/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 28/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 29/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 30/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 31/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 32/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 33/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 34/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 2, 'knight_1': 1}\n",
      "Episode 35/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 36/100 - Rewards: {'archer_0': 0, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 37/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 38/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 39/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 40/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 1, 'knight_1': 1}\n",
      "Episode 41/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 42/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 43/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 44/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 45/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 46/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 47/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 48/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 49/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 50/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 51/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 52/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 53/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 54/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 55/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 56/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 57/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 58/100 - Rewards: {'archer_0': 0, 'archer_1': 2, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 59/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 60/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 61/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 62/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 63/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 64/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 65/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 66/100 - Rewards: {'archer_0': 0, 'archer_1': 1, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 67/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 68/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 69/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 70/100 - Rewards: {'archer_0': 5, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 71/100 - Rewards: {'archer_0': 1, 'archer_1': 2, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 72/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 2}\n",
      "Episode 73/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 74/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 75/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 76/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 77/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 78/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 79/100 - Rewards: {'archer_0': 3, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 80/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 81/100 - Rewards: {'archer_0': 2, 'archer_1': 2, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 82/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 2, 'knight_1': 0}\n",
      "Episode 83/100 - Rewards: {'archer_0': 2, 'archer_1': 1, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 84/100 - Rewards: {'archer_0': 4, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 85/100 - Rewards: {'archer_0': 0, 'archer_1': 2, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 86/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 87/100 - Rewards: {'archer_0': 6, 'archer_1': 2, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 88/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 89/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 90/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 91/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 92/100 - Rewards: {'archer_0': 9, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 93/100 - Rewards: {'archer_0': 1, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 94/100 - Rewards: {'archer_0': 1, 'archer_1': 1, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 95/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 96/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 97/100 - Rewards: {'archer_0': 2, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n",
      "Episode 98/100 - Rewards: {'archer_0': 0, 'archer_1': 1, 'knight_0': 0, 'knight_1': 1}\n",
      "Episode 99/100 - Rewards: {'archer_0': 0, 'archer_1': 0, 'knight_0': 0, 'knight_1': 0}\n",
      "Episode 100/100 - Rewards: {'archer_0': 5, 'archer_1': 0, 'knight_0': 1, 'knight_1': 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Sauvegarde de la vidéo\u001b[39;00m\n\u001b[0;32m     48\u001b[0m imageio\u001b[38;5;241m.\u001b[39mmimsave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_dqn_knights_archers_zombies.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, frames, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall_dqn_knights_archers_zombies.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imageio\\v2.py:362\u001b[0m, in \u001b[0;36mmimwrite\u001b[1;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite(ims, is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:253\u001b[0m, in \u001b[0;36mLegacyPlugin.write\u001b[1;34m(self, ndimage, is_batch, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(image\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mnumber) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\n\u001b[0;32m    247\u001b[0m             image\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m    248\u001b[0m         ):\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    250\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll images have to be numeric, and not `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m             )\n\u001b[1;32m--> 253\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m writer\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imageio\\core\\format.py:590\u001b[0m, in \u001b[0;36mFormat.Writer.append_data\u001b[1;34m(self, im, meta)\u001b[0m\n\u001b[0;32m    588\u001b[0m im \u001b[38;5;241m=\u001b[39m asarray(im)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# Call\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_meta\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imageio\\plugins\\ffmpeg.py:604\u001b[0m, in \u001b[0;36mFfmpegFormat.Writer._append_data\u001b[1;34m(self, im, meta)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Check status\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# Write. Yes, we can send the data in as a numpy array\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\imageio_ffmpeg\\_io.py:627\u001b[0m, in \u001b[0;36mwrite_frames\u001b[1;34m(path, size, pix_fmt_in, pix_fmt_out, fps, quality, bitrate, codec, macro_block_size, ffmpeg_log_level, ffmpeg_timeout, input_params, output_params, audio_path, audio_codec)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# framesize = size[0] * size[1] * depth * bpp\u001b[39;00m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;66;03m# assert isinstance(bb, bytes), \"Frame must be send as bytes\"\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;66;03m# assert len(bb) == framesize, \"Frame must have width*height*depth*bpp bytes\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m \n\u001b[0;32m    625\u001b[0m \u001b[38;5;66;03m# Write\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Show the command and stderr from pipe\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFFMPEG COMMAND:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1:}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFFMPEG STDERR \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUTPUT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(err, cmd_str)\n\u001b[0;32m    633\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env = knights_archers_zombies_v10.env(render_mode=\"rgb_array\")\n",
    "env = aec_to_parallel(env)\n",
    "env.reset()\n",
    "frames = []\n",
    "allframes = []\n",
    "best_frames = []\n",
    "best_reward = 0\n",
    "\n",
    "# Charger les réseaux Q\n",
    "q_networks = {agent: QNetwork(state_dims, action_dims) for agent in agents}\n",
    "for agent in agents:\n",
    "    q_networks[agent].load_state_dict(torch.load(f\"q_network_agent_{agent}_knights_archers_zombies.pt\"))\n",
    "\n",
    "# Evaluation des agents\n",
    "num_episodes = 50\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state,_ = env.reset()\n",
    "    done = {agent: False for agent in agents}\n",
    "    episode_reward = {agent: 0 for agent in agents}\n",
    "    frames = []\n",
    "\n",
    "    while not all(done.values()):\n",
    "        actions = {}\n",
    "        for agent in agents:\n",
    "            if not done[agent]:\n",
    "                with torch.no_grad():\n",
    "                    action = torch.argmax(q_networks[agent](torch.FloatTensor(state[agent].flatten()))).item()\n",
    "                actions[agent] = action\n",
    "\n",
    "        next_state, rewards, dones, _, _= env.step(actions)\n",
    "        frames.append(env.render())\n",
    "        allframes.append(frames[-1])\n",
    "\n",
    "        for agent in agents:\n",
    "            if not done[agent]:\n",
    "                episode_reward[agent] += rewards[agent]\n",
    "                done[agent] = dones[agent]\n",
    "                state[agent] = next_state[agent]\n",
    "\n",
    "    if sum(episode_reward.values()) > best_reward:\n",
    "        best_reward = sum(episode_reward.values())\n",
    "        best_frames = frames\n",
    "\n",
    "    print(f\"Episode {episode + 1}/{num_episodes} - Rewards: {episode_reward}\")\n",
    "\n",
    "# Sauvegarde de la vidéo\n",
    "imageio.mimsave(\"best_dqn_knights_archers_zombies.mp4\", frames, fps=15)\n",
    "# imageio.mimsave(\"all_dqn_knights_archers_zombies.mp4\", allframes, fps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
